{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLOv7 Tiny IINT8 Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.0+cpu\n",
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "# print(sys.path)\n",
    "sys.path.append(\"/home/gjraza/aletheia_ai/interview_task/yolov7\")\n",
    "import torch \n",
    "print (torch.__version__)\n",
    "\n",
    "import pytorch_quantization\n",
    "print (pytorch_quantization.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imported\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "from models.experimental import attempt_load\n",
    "from utils.datasets import create_dataloader\n",
    "from utils.general import coco80_to_coco91_class, check_dataset, check_file, check_img_size, check_requirements, \\\n",
    "    box_iou, non_max_suppression, scale_coords, xyxy2xywh, xywh2xyxy, set_logging, increment_path, colorstr\n",
    "from utils.metrics import ap_per_class, ConfusionMatrix\n",
    "from utils.plots import plot_images, output_to_target, plot_study_txt\n",
    "from utils.torch_utils import select_device, time_synchronized, TracedModel\n",
    "\n",
    "\n",
    "print ('imported')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FP32 model and dataset setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_cls = False\n",
    "device = 'cpu'\n",
    "weights  = '/home/gjraza/aletheia_ai/interview_task/yolov7/runs_colab/train/yolov7-tiny-crowd-human-1000-2/weights/best.pt'\n",
    "imgsz = 640\n",
    "single_cls = False\n",
    "batch_size = 1\n",
    "augment = False\n",
    "save_hybrid = False \n",
    "conf_thres = 0.001\n",
    "iou_thres = 0.5\n",
    "verbose = True\n",
    "training = False\n",
    "save_dir = 'runs/test/yolov7-tiny-crowd-human-pt-quant-test'\n",
    "data = '/home/gjraza/aletheia_ai/interview_task/yolov7/data/data_crowd_human_yolo.yaml'\n",
    "task = 'val'\n",
    "\n",
    "\n",
    "class options:\n",
    "    def __init__(self):\n",
    "        self.single_cls = False\n",
    "        self.device = 'cpu'\n",
    "        self.weights  = '/home/gjraza/aletheia_ai/interview_task/yolov7/runs_colab/train/yolov7-tiny-crowd-human-1000-2/weights/best.pt'\n",
    "        self.imgsz = 640\n",
    "        self.single_cls = False\n",
    "        self.batch_size = 1\n",
    "        self.augment = False\n",
    "        self.save_hybrid = False \n",
    "        self.conf_thres = 0.001\n",
    "        self.iou_thres = 0.5\n",
    "        self.verbose = True\n",
    "        self.training = False\n",
    "        self.save_dir = 'runs/test/yolov7-tiny-crowd-human-pt-quant-test'\n",
    "        self.data = '/home/gjraza/aletheia_ai/interview_task/yolov7/data/data_crowd_human_yolo.yaml'\n",
    "\n",
    "opt = options()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/gjraza/aletheia_ai/interview_task/yolov7/runs_colab/train/yolov7-tiny-crowd-human-1000-2/weights/best.pt'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1203 21:11:27.792776 140684794753408 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I1203 21:11:27.797751 140684794753408 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I1203 21:11:27.801338 140684794753408 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I1203 21:11:27.804241 140684794753408 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I1203 21:11:27.822010 140684794753408 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I1203 21:11:27.834161 140684794753408 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I1203 21:11:27.835983 140684794753408 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I1203 21:11:27.837439 140684794753408 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I1203 21:11:27.857929 140684794753408 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I1203 21:11:27.859054 140684794753408 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I1203 21:11:27.860094 140684794753408 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I1203 21:11:27.861379 140684794753408 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I1203 21:11:27.880429 140684794753408 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I1203 21:11:27.881757 140684794753408 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I1203 21:11:27.883121 140684794753408 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I1203 21:11:27.884542 140684794753408 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I1203 21:11:27.901920 140684794753408 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I1203 21:11:27.902717 140684794753408 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I1203 21:11:27.903590 140684794753408 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I1203 21:11:27.904465 140684794753408 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I1203 21:11:27.947784 140684794753408 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I1203 21:11:27.949959 140684794753408 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I1203 21:11:27.951197 140684794753408 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I1203 21:11:27.952450 140684794753408 tensor_quantizer.py:105] Creating Max calibrator\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1203 21:11:27.987073 140684794753408 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I1203 21:11:27.992374 140684794753408 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I1203 21:11:27.997444 140684794753408 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I1203 21:11:28.000707 140684794753408 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I1203 21:11:28.031716 140684794753408 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I1203 21:11:28.035336 140684794753408 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I1203 21:11:28.039470 140684794753408 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I1203 21:11:28.048306 140684794753408 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I1203 21:11:28.074259 140684794753408 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I1203 21:11:28.075912 140684794753408 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I1203 21:11:28.077433 140684794753408 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I1203 21:11:28.079282 140684794753408 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I1203 21:11:28.103847 140684794753408 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I1203 21:11:28.110154 140684794753408 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I1203 21:11:28.113447 140684794753408 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I1203 21:11:28.114559 140684794753408 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I1203 21:11:28.134917 140684794753408 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I1203 21:11:28.136651 140684794753408 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I1203 21:11:28.137979 140684794753408 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I1203 21:11:28.139254 140684794753408 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I1203 21:11:28.163957 140684794753408 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I1203 21:11:28.165473 140684794753408 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I1203 21:11:28.166675 140684794753408 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I1203 21:11:28.167895 140684794753408 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I1203 21:11:28.190674 140684794753408 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I1203 21:11:28.192224 140684794753408 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I1203 21:11:28.203086 140684794753408 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I1203 21:11:28.204131 140684794753408 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I1203 21:11:28.221466 140684794753408 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I1203 21:11:28.224087 140684794753408 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I1203 21:11:28.225205 140684794753408 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I1203 21:11:28.226462 140684794753408 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I1203 21:11:28.258108 140684794753408 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I1203 21:11:28.258860 140684794753408 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I1203 21:11:28.259804 140684794753408 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I1203 21:11:28.260926 140684794753408 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I1203 21:11:28.279778 140684794753408 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I1203 21:11:28.280833 140684794753408 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I1203 21:11:28.282034 140684794753408 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I1203 21:11:28.282935 140684794753408 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I1203 21:11:28.315804 140684794753408 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I1203 21:11:28.316989 140684794753408 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I1203 21:11:28.318131 140684794753408 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I1203 21:11:28.319847 140684794753408 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I1203 21:11:28.348384 140684794753408 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I1203 21:11:28.352278 140684794753408 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I1203 21:11:28.353110 140684794753408 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I1203 21:11:28.354362 140684794753408 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I1203 21:11:28.373249 140684794753408 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I1203 21:11:28.374210 140684794753408 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I1203 21:11:28.375387 140684794753408 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I1203 21:11:28.376129 140684794753408 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I1203 21:11:28.403384 140684794753408 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I1203 21:11:28.404806 140684794753408 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I1203 21:11:28.406133 140684794753408 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I1203 21:11:28.407667 140684794753408 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I1203 21:11:28.467072 140684794753408 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I1203 21:11:28.467994 140684794753408 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I1203 21:11:28.472441 140684794753408 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I1203 21:11:28.473291 140684794753408 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I1203 21:11:28.507250 140684794753408 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I1203 21:11:28.508031 140684794753408 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I1203 21:11:28.509327 140684794753408 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I1203 21:11:28.510875 140684794753408 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I1203 21:11:28.543362 140684794753408 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I1203 21:11:28.544477 140684794753408 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I1203 21:11:28.545320 140684794753408 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I1203 21:11:28.546675 140684794753408 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I1203 21:11:28.565793 140684794753408 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I1203 21:11:28.566644 140684794753408 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I1203 21:11:28.567364 140684794753408 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I1203 21:11:28.568682 140684794753408 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I1203 21:11:28.591081 140684794753408 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I1203 21:11:28.591792 140684794753408 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I1203 21:11:28.593566 140684794753408 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I1203 21:11:28.596555 140684794753408 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I1203 21:11:28.624130 140684794753408 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I1203 21:11:28.624953 140684794753408 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I1203 21:11:28.626315 140684794753408 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I1203 21:11:28.627349 140684794753408 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I1203 21:11:28.651815 140684794753408 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I1203 21:11:28.655012 140684794753408 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I1203 21:11:28.655819 140684794753408 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I1203 21:11:28.656937 140684794753408 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I1203 21:11:28.672578 140684794753408 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I1203 21:11:28.674324 140684794753408 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I1203 21:11:28.675413 140684794753408 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I1203 21:11:28.676158 140684794753408 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I1203 21:11:28.694626 140684794753408 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I1203 21:11:28.695474 140684794753408 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I1203 21:11:28.696190 140684794753408 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I1203 21:11:28.697544 140684794753408 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I1203 21:11:28.715168 140684794753408 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I1203 21:11:28.716785 140684794753408 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I1203 21:11:28.717602 140684794753408 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I1203 21:11:28.718884 140684794753408 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I1203 21:11:28.740019 140684794753408 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I1203 21:11:28.741031 140684794753408 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I1203 21:11:28.745446 140684794753408 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I1203 21:11:28.746416 140684794753408 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I1203 21:11:28.768419 140684794753408 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I1203 21:11:28.769230 140684794753408 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I1203 21:11:28.771089 140684794753408 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I1203 21:11:28.772382 140684794753408 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I1203 21:11:28.793340 140684794753408 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I1203 21:11:28.794203 140684794753408 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I1203 21:11:28.795435 140684794753408 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I1203 21:11:28.796584 140684794753408 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I1203 21:11:28.818295 140684794753408 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I1203 21:11:28.819693 140684794753408 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I1203 21:11:28.821583 140684794753408 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I1203 21:11:28.823084 140684794753408 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I1203 21:11:28.842942 140684794753408 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I1203 21:11:28.844356 140684794753408 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I1203 21:11:28.845696 140684794753408 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I1203 21:11:28.847033 140684794753408 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I1203 21:11:28.865602 140684794753408 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I1203 21:11:28.866405 140684794753408 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I1203 21:11:28.869433 140684794753408 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I1203 21:11:28.870201 140684794753408 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I1203 21:11:28.897605 140684794753408 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I1203 21:11:28.899106 140684794753408 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I1203 21:11:28.900063 140684794753408 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I1203 21:11:28.901008 140684794753408 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I1203 21:11:28.920663 140684794753408 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I1203 21:11:28.922399 140684794753408 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I1203 21:11:28.923682 140684794753408 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I1203 21:11:28.924695 140684794753408 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I1203 21:11:28.941124 140684794753408 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I1203 21:11:28.942231 140684794753408 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I1203 21:11:28.944911 140684794753408 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I1203 21:11:28.946059 140684794753408 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I1203 21:11:28.968605 140684794753408 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I1203 21:11:28.969471 140684794753408 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I1203 21:11:28.970407 140684794753408 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I1203 21:11:28.971773 140684794753408 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I1203 21:11:28.993528 140684794753408 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I1203 21:11:28.994386 140684794753408 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I1203 21:11:28.995599 140684794753408 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I1203 21:11:28.996861 140684794753408 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I1203 21:11:29.017988 140684794753408 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I1203 21:11:29.018744 140684794753408 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I1203 21:11:29.019503 140684794753408 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I1203 21:11:29.021427 140684794753408 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I1203 21:11:29.039530 140684794753408 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I1203 21:11:29.040871 140684794753408 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I1203 21:11:29.042189 140684794753408 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I1203 21:11:29.043569 140684794753408 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I1203 21:11:29.067158 140684794753408 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I1203 21:11:29.068144 140684794753408 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I1203 21:11:29.069312 140684794753408 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I1203 21:11:29.070572 140684794753408 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I1203 21:11:29.090198 140684794753408 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I1203 21:11:29.093421 140684794753408 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I1203 21:11:29.094418 140684794753408 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I1203 21:11:29.095423 140684794753408 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I1203 21:11:29.117843 140684794753408 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I1203 21:11:29.118519 140684794753408 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I1203 21:11:29.124089 140684794753408 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I1203 21:11:29.124973 140684794753408 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I1203 21:11:29.147185 140684794753408 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I1203 21:11:29.148681 140684794753408 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I1203 21:11:29.149558 140684794753408 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I1203 21:11:29.151428 140684794753408 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I1203 21:11:29.176393 140684794753408 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I1203 21:11:29.177785 140684794753408 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I1203 21:11:29.178857 140684794753408 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I1203 21:11:29.180268 140684794753408 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I1203 21:11:29.203870 140684794753408 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I1203 21:11:29.207847 140684794753408 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I1203 21:11:29.211416 140684794753408 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I1203 21:11:29.212432 140684794753408 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I1203 21:11:29.275099 140684794753408 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I1203 21:11:29.275740 140684794753408 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I1203 21:11:29.276402 140684794753408 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I1203 21:11:29.277468 140684794753408 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I1203 21:11:29.303865 140684794753408 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I1203 21:11:29.305113 140684794753408 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I1203 21:11:29.306177 140684794753408 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I1203 21:11:29.307181 140684794753408 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I1203 21:11:29.397307 140684794753408 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I1203 21:11:29.401771 140684794753408 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I1203 21:11:29.407190 140684794753408 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I1203 21:11:29.412575 140684794753408 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I1203 21:11:29.463217 140684794753408 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I1203 21:11:29.467053 140684794753408 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I1203 21:11:29.471033 140684794753408 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I1203 21:11:29.474871 140684794753408 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I1203 21:11:29.501271 140684794753408 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I1203 21:11:29.502691 140684794753408 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I1203 21:11:29.507012 140684794753408 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I1203 21:11:29.508491 140684794753408 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I1203 21:11:29.546706 140684794753408 _utils.py:72] Input is fake quantized to 8 bits in QuantConv2d with axis None!\n",
      "I1203 21:11:29.551123 140684794753408 _utils.py:75] Weight is fake quantized to 8 bits in QuantConv2d with axis 0!\n",
      "I1203 21:11:29.555482 140684794753408 tensor_quantizer.py:101] Creating histogram calibrator\n",
      "I1203 21:11:29.559223 140684794753408 tensor_quantizer.py:105] Creating Max calibrator\n",
      "I1203 21:11:29.825568 140684794753408 torch_utils.py:225] Model Summary: 318 layers, 6010302 parameters, 0 gradients, 0.1 GFLOPS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDetect.fuse\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (model): Sequential(\n",
       "    (0): Conv(\n",
       "      (conv): QuantConv2d(\n",
       "        3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)\n",
       "        (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "        (_weight_quantizer): TensorQuantizer(8bit narrow fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (1): Conv(\n",
       "      (conv): QuantConv2d(\n",
       "        32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)\n",
       "        (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "        (_weight_quantizer): TensorQuantizer(8bit narrow fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (2): Conv(\n",
       "      (conv): QuantConv2d(\n",
       "        64, 32, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "        (_weight_quantizer): TensorQuantizer(8bit narrow fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (3): Conv(\n",
       "      (conv): QuantConv2d(\n",
       "        64, 32, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "        (_weight_quantizer): TensorQuantizer(8bit narrow fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (4): Conv(\n",
       "      (conv): QuantConv2d(\n",
       "        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "        (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "        (_weight_quantizer): TensorQuantizer(8bit narrow fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (5): Conv(\n",
       "      (conv): QuantConv2d(\n",
       "        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "        (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "        (_weight_quantizer): TensorQuantizer(8bit narrow fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (6): Concat()\n",
       "    (7): Conv(\n",
       "      (conv): QuantConv2d(\n",
       "        128, 64, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "        (_weight_quantizer): TensorQuantizer(8bit narrow fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (8): MP(\n",
       "      (m): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (9): Conv(\n",
       "      (conv): QuantConv2d(\n",
       "        64, 64, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "        (_weight_quantizer): TensorQuantizer(8bit narrow fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (10): Conv(\n",
       "      (conv): QuantConv2d(\n",
       "        64, 64, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "        (_weight_quantizer): TensorQuantizer(8bit narrow fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (11): Conv(\n",
       "      (conv): QuantConv2d(\n",
       "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "        (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "        (_weight_quantizer): TensorQuantizer(8bit narrow fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (12): Conv(\n",
       "      (conv): QuantConv2d(\n",
       "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "        (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "        (_weight_quantizer): TensorQuantizer(8bit narrow fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (13): Concat()\n",
       "    (14): Conv(\n",
       "      (conv): QuantConv2d(\n",
       "        256, 128, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "        (_weight_quantizer): TensorQuantizer(8bit narrow fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (15): MP(\n",
       "      (m): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (16): Conv(\n",
       "      (conv): QuantConv2d(\n",
       "        128, 128, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "        (_weight_quantizer): TensorQuantizer(8bit narrow fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (17): Conv(\n",
       "      (conv): QuantConv2d(\n",
       "        128, 128, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "        (_weight_quantizer): TensorQuantizer(8bit narrow fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (18): Conv(\n",
       "      (conv): QuantConv2d(\n",
       "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "        (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "        (_weight_quantizer): TensorQuantizer(8bit narrow fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (19): Conv(\n",
       "      (conv): QuantConv2d(\n",
       "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "        (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "        (_weight_quantizer): TensorQuantizer(8bit narrow fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (20): Concat()\n",
       "    (21): Conv(\n",
       "      (conv): QuantConv2d(\n",
       "        512, 256, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "        (_weight_quantizer): TensorQuantizer(8bit narrow fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (22): MP(\n",
       "      (m): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (23): Conv(\n",
       "      (conv): QuantConv2d(\n",
       "        256, 256, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "        (_weight_quantizer): TensorQuantizer(8bit narrow fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (24): Conv(\n",
       "      (conv): QuantConv2d(\n",
       "        256, 256, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "        (_weight_quantizer): TensorQuantizer(8bit narrow fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (25): Conv(\n",
       "      (conv): QuantConv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "        (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "        (_weight_quantizer): TensorQuantizer(8bit narrow fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (26): Conv(\n",
       "      (conv): QuantConv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "        (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "        (_weight_quantizer): TensorQuantizer(8bit narrow fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (27): Concat()\n",
       "    (28): Conv(\n",
       "      (conv): QuantConv2d(\n",
       "        1024, 512, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "        (_weight_quantizer): TensorQuantizer(8bit narrow fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (29): Conv(\n",
       "      (conv): QuantConv2d(\n",
       "        512, 256, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "        (_weight_quantizer): TensorQuantizer(8bit narrow fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (30): Conv(\n",
       "      (conv): QuantConv2d(\n",
       "        512, 256, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "        (_weight_quantizer): TensorQuantizer(8bit narrow fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (31): SP(\n",
       "      (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (32): SP(\n",
       "      (m): MaxPool2d(kernel_size=9, stride=1, padding=4, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (33): SP(\n",
       "      (m): MaxPool2d(kernel_size=13, stride=1, padding=6, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (34): Concat()\n",
       "    (35): Conv(\n",
       "      (conv): QuantConv2d(\n",
       "        1024, 256, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "        (_weight_quantizer): TensorQuantizer(8bit narrow fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (36): Concat()\n",
       "    (37): Conv(\n",
       "      (conv): QuantConv2d(\n",
       "        512, 256, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "        (_weight_quantizer): TensorQuantizer(8bit narrow fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (38): Conv(\n",
       "      (conv): QuantConv2d(\n",
       "        256, 128, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "        (_weight_quantizer): TensorQuantizer(8bit narrow fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (39): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (40): Conv(\n",
       "      (conv): QuantConv2d(\n",
       "        256, 128, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "        (_weight_quantizer): TensorQuantizer(8bit narrow fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (41): Concat()\n",
       "    (42): Conv(\n",
       "      (conv): QuantConv2d(\n",
       "        256, 64, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "        (_weight_quantizer): TensorQuantizer(8bit narrow fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (43): Conv(\n",
       "      (conv): QuantConv2d(\n",
       "        256, 64, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "        (_weight_quantizer): TensorQuantizer(8bit narrow fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (44): Conv(\n",
       "      (conv): QuantConv2d(\n",
       "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "        (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "        (_weight_quantizer): TensorQuantizer(8bit narrow fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (45): Conv(\n",
       "      (conv): QuantConv2d(\n",
       "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "        (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "        (_weight_quantizer): TensorQuantizer(8bit narrow fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (46): Concat()\n",
       "    (47): Conv(\n",
       "      (conv): QuantConv2d(\n",
       "        256, 128, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "        (_weight_quantizer): TensorQuantizer(8bit narrow fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (48): Conv(\n",
       "      (conv): QuantConv2d(\n",
       "        128, 64, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "        (_weight_quantizer): TensorQuantizer(8bit narrow fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (49): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (50): Conv(\n",
       "      (conv): QuantConv2d(\n",
       "        128, 64, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "        (_weight_quantizer): TensorQuantizer(8bit narrow fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (51): Concat()\n",
       "    (52): Conv(\n",
       "      (conv): QuantConv2d(\n",
       "        128, 32, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "        (_weight_quantizer): TensorQuantizer(8bit narrow fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (53): Conv(\n",
       "      (conv): QuantConv2d(\n",
       "        128, 32, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "        (_weight_quantizer): TensorQuantizer(8bit narrow fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (54): Conv(\n",
       "      (conv): QuantConv2d(\n",
       "        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "        (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "        (_weight_quantizer): TensorQuantizer(8bit narrow fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (55): Conv(\n",
       "      (conv): QuantConv2d(\n",
       "        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "        (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "        (_weight_quantizer): TensorQuantizer(8bit narrow fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (56): Concat()\n",
       "    (57): Conv(\n",
       "      (conv): QuantConv2d(\n",
       "        128, 64, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "        (_weight_quantizer): TensorQuantizer(8bit narrow fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (58): Conv(\n",
       "      (conv): QuantConv2d(\n",
       "        64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)\n",
       "        (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "        (_weight_quantizer): TensorQuantizer(8bit narrow fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (59): Concat()\n",
       "    (60): Conv(\n",
       "      (conv): QuantConv2d(\n",
       "        256, 64, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "        (_weight_quantizer): TensorQuantizer(8bit narrow fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (61): Conv(\n",
       "      (conv): QuantConv2d(\n",
       "        256, 64, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "        (_weight_quantizer): TensorQuantizer(8bit narrow fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (62): Conv(\n",
       "      (conv): QuantConv2d(\n",
       "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "        (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "        (_weight_quantizer): TensorQuantizer(8bit narrow fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (63): Conv(\n",
       "      (conv): QuantConv2d(\n",
       "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "        (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "        (_weight_quantizer): TensorQuantizer(8bit narrow fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (64): Concat()\n",
       "    (65): Conv(\n",
       "      (conv): QuantConv2d(\n",
       "        256, 128, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "        (_weight_quantizer): TensorQuantizer(8bit narrow fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (66): Conv(\n",
       "      (conv): QuantConv2d(\n",
       "        128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)\n",
       "        (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "        (_weight_quantizer): TensorQuantizer(8bit narrow fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (67): Concat()\n",
       "    (68): Conv(\n",
       "      (conv): QuantConv2d(\n",
       "        512, 128, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "        (_weight_quantizer): TensorQuantizer(8bit narrow fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (69): Conv(\n",
       "      (conv): QuantConv2d(\n",
       "        512, 128, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "        (_weight_quantizer): TensorQuantizer(8bit narrow fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (70): Conv(\n",
       "      (conv): QuantConv2d(\n",
       "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "        (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "        (_weight_quantizer): TensorQuantizer(8bit narrow fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (71): Conv(\n",
       "      (conv): QuantConv2d(\n",
       "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "        (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "        (_weight_quantizer): TensorQuantizer(8bit narrow fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (72): Concat()\n",
       "    (73): Conv(\n",
       "      (conv): QuantConv2d(\n",
       "        512, 256, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "        (_weight_quantizer): TensorQuantizer(8bit narrow fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (74): Conv(\n",
       "      (conv): QuantConv2d(\n",
       "        64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "        (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "        (_weight_quantizer): TensorQuantizer(8bit narrow fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (75): Conv(\n",
       "      (conv): QuantConv2d(\n",
       "        128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "        (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "        (_weight_quantizer): TensorQuantizer(8bit narrow fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (76): Conv(\n",
       "      (conv): QuantConv2d(\n",
       "        256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "        (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "        (_weight_quantizer): TensorQuantizer(8bit narrow fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (77): IDetect(\n",
       "      (m): ModuleList(\n",
       "        (0): Conv2d(128, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): Conv2d(512, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (ia): ModuleList(\n",
       "        (0): ImplicitA()\n",
       "        (1): ImplicitA()\n",
       "        (2): ImplicitA()\n",
       "      )\n",
       "      (im): ModuleList(\n",
       "        (0): ImplicitM()\n",
       "        (1): ImplicitM()\n",
       "        (2): ImplicitM()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = attempt_load(opt.weights, map_location=opt.device)  # load FP32 model\n",
    "model.eval()\n",
    "# print (model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640\n"
     ]
    }
   ],
   "source": [
    "gs = max(int(model.stride.max()), 32)  # grid size (max stride)\n",
    "imgsz = check_img_size(imgsz, s=gs)  # check img_size\n",
    "print (imgsz)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla FP32 Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "tensor([0.50000, 0.55000, 0.60000, 0.65000, 0.70000, 0.75000, 0.80000, 0.85000, 0.90000, 0.95000])\n",
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/my_data/datasets/crowd_human_yolo_1000/valid/labels.cache' images and labels... 200 found, 0 missing, 0 empty, 0 corrupted: 100%|| 200/200 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "names:\n",
      " {0: 'person', 1: 'head'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100%|| 200/200 [01:41<00:00,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         200        8622       0.839       0.597       0.678       0.341\n",
      "              person         200        4311       0.845       0.646       0.737        0.39\n",
      "                head         200        4311       0.834       0.548        0.62       0.293\n",
      "Speed: 460.7/4.2/464.9 ms inference/NMS/total per 640x640 image at batch-size 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def eval(model):\n",
    "\n",
    "    \n",
    "    single_cls = False\n",
    "    device = 'cpu'\n",
    "    imgsz = 640\n",
    "    single_cls = False\n",
    "    batch_size = 1\n",
    "    augment = False\n",
    "    save_hybrid = False \n",
    "    conf_thres = 0.001\n",
    "    iou_thres = 0.5\n",
    "    verbose = True\n",
    "    training = False\n",
    "    save_dir = 'runs/test/yolov7-tiny-crowd-human-pt-quant-test'\n",
    "    gs = max(int(model.stride.max()), 32)  # grid size (max stride)\n",
    "    imgsz = check_img_size(imgsz, s=gs)  # check img_size\n",
    "    data = '/home/gjraza/aletheia_ai/interview_task/yolov7/data/data_crowd_human_yolo.yaml'\n",
    "\n",
    "\n",
    "\n",
    "    if isinstance(opt.data, str):\n",
    "        is_coco = opt.data.endswith('coco.yaml')\n",
    "        with open(data) as f:\n",
    "            data = yaml.load(f, Loader=yaml.SafeLoader)\n",
    "    check_dataset(data)  # check\n",
    "    nc = 1 if single_cls else int(data['nc'])  # number of classes\n",
    "    iouv = torch.linspace(0.5, 0.95, 10).to(device)  # iou vector for mAP@0.5:0.95\n",
    "    niou = iouv.numel()\n",
    "    print (nc)\n",
    "    print (iouv)\n",
    "    print (niou)\n",
    "    # Dataloader\n",
    "\n",
    "    if device != 'cpu':\n",
    "        model(torch.zeros(1, 3, imgsz, imgsz).to(device).type_as(next(model.parameters())))  # run once\n",
    "    task = 'val'  # path to train/val/test images\n",
    "    dataloader = create_dataloader(data[task], imgsz, batch_size, gs, opt, pad=0.5, rect=False,\n",
    "                                    prefix=colorstr(f'{task}: '))[0]\n",
    "\n",
    "\n",
    "    seen = 0\n",
    "    confusion_matrix = ConfusionMatrix(nc=nc)\n",
    "    names = {k: v for k, v in enumerate(model.names if hasattr(model, 'names') else model.module.names)}\n",
    "    print ('names:\\n', names)\n",
    "    coco91class = coco80_to_coco91_class()\n",
    "    s = ('%20s' + '%12s' * 6) % ('Class', 'Images', 'Labels', 'P', 'R', 'mAP@.5', 'mAP@.5:.95')\n",
    "    p, r, f1, mp, mr, map50, map, t0, t1 = 0., 0., 0., 0., 0., 0., 0., 0., 0.\n",
    "    loss = torch.zeros(3, device=device)\n",
    "    jdict, stats, ap, ap_class, wandb_images = [], [], [], [], []\n",
    "\n",
    "\n",
    "    for batch_i, (img, targets, paths, shapes) in enumerate(tqdm(dataloader, desc=s)):\n",
    "            img = img.to(device, non_blocking=True)\n",
    "            img =  img.float()  # uint8 to fp16/32\n",
    "            img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
    "            targets = targets.to(device)\n",
    "            nb, _, height, width = img.shape  # batch size, channels, height, width\n",
    "            # print (img.shape)\n",
    "            with torch.no_grad():\n",
    "                # Run model\n",
    "                t = time_synchronized()\n",
    "                out, train_out = model(img, augment=augment)  # inference and training outputs\n",
    "                t0 += time_synchronized() - t\n",
    "\n",
    "                # # Compute loss\n",
    "                # if compute_loss:\n",
    "                #     loss += compute_loss([x.float() for x in train_out], targets)[1][:3]  # box, obj, cls\n",
    "\n",
    "                # Run NMS\n",
    "                targets[:, 2:] *= torch.Tensor([width, height, width, height]).to(device)  # to pixels\n",
    "                lb = [targets[targets[:, 0] == i, 1:] for i in range(nb)] if save_hybrid else []  # for autolabelling\n",
    "                t = time_synchronized()\n",
    "                out = non_max_suppression(out, conf_thres=conf_thres, iou_thres=iou_thres, labels=lb, multi_label=True)\n",
    "                t1 += time_synchronized() - t\n",
    "\n",
    "            # Statistics per image\n",
    "            for si, pred in enumerate(out):\n",
    "                labels = targets[targets[:, 0] == si, 1:]\n",
    "                nl = len(labels)\n",
    "                tcls = labels[:, 0].tolist() if nl else []  # target class\n",
    "                path = Path(paths[si])\n",
    "                seen += 1\n",
    "\n",
    "                if len(pred) == 0:\n",
    "                    if nl:\n",
    "                        stats.append((torch.zeros(0, niou, dtype=torch.bool), torch.Tensor(), torch.Tensor(), tcls))\n",
    "                    continue\n",
    "\n",
    "                # Predictions\n",
    "                predn = pred.clone()\n",
    "                scale_coords(img[si].shape[1:], predn[:, :4], shapes[si][0], shapes[si][1])  # native-space pred\n",
    "\n",
    "\n",
    "                # Assign all predictions as incorrect\n",
    "                correct = torch.zeros(pred.shape[0], niou, dtype=torch.bool, device=device)\n",
    "                if nl:\n",
    "                    detected = []  # target indices\n",
    "                    tcls_tensor = labels[:, 0]\n",
    "\n",
    "                    # target boxes\n",
    "                    tbox = xywh2xyxy(labels[:, 1:5])\n",
    "                    scale_coords(img[si].shape[1:], tbox, shapes[si][0], shapes[si][1])  # native-space labels\n",
    "\n",
    "                    # Per target class\n",
    "                    for cls in torch.unique(tcls_tensor):\n",
    "                        ti = (cls == tcls_tensor).nonzero(as_tuple=False).view(-1)  # prediction indices\n",
    "                        pi = (cls == pred[:, 5]).nonzero(as_tuple=False).view(-1)  # target indices\n",
    "\n",
    "                        # Search for detections\n",
    "                        if pi.shape[0]:\n",
    "                            # Prediction to target ious\n",
    "                            ious, i = box_iou(predn[pi, :4], tbox[ti]).max(1)  # best ious, indices\n",
    "\n",
    "                            # Append detections\n",
    "                            detected_set = set()\n",
    "                            for j in (ious > iouv[0]).nonzero(as_tuple=False):\n",
    "                                d = ti[i[j]]  # detected target\n",
    "                                if d.item() not in detected_set:\n",
    "                                    detected_set.add(d.item())\n",
    "                                    detected.append(d)\n",
    "                                    correct[pi[j]] = ious[j] > iouv  # iou_thres is 1xn\n",
    "                                    if len(detected) == nl:  # all targets already located in image\n",
    "                                        break\n",
    "\n",
    "                # Append statistics (correct, conf, pcls, tcls)\n",
    "                stats.append((correct.cpu(), pred[:, 4].cpu(), pred[:, 5].cpu(), tcls))\n",
    "\n",
    "\n",
    "    # Compute statistics\n",
    "    stats = [np.concatenate(x, 0) for x in zip(*stats)]  # to numpy\n",
    "    if len(stats) and stats[0].any():\n",
    "        p, r, ap, f1, ap_class = ap_per_class(*stats, plot=False, v5_metric=False, save_dir=save_dir, names=names)\n",
    "        ap50, ap = ap[:, 0], ap.mean(1)  # AP@0.5, AP@0.5:0.95\n",
    "        mp, mr, map50, map = p.mean(), r.mean(), ap50.mean(), ap.mean()\n",
    "        nt = np.bincount(stats[3].astype(np.int64), minlength=nc)  # number of targets per class\n",
    "    else:\n",
    "        nt = torch.zeros(1)\n",
    "\n",
    "    # Print results\n",
    "    pf = '%20s' + '%12i' * 2 + '%12.3g' * 4  # print format\n",
    "    print(pf % ('all', seen, nt.sum(), mp, mr, map50, map))\n",
    "\n",
    "    # Print results per class\n",
    "    if (verbose or (nc < 50 and not training)) and nc > 1 and len(stats):\n",
    "        for i, c in enumerate(ap_class):\n",
    "            print(pf % (names[c], seen, nt[c], p[i], r[i], ap50[i], ap[i]))\n",
    "\n",
    "    # Print speeds\n",
    "    t = tuple(x / seen * 1E3 for x in (t0, t1, t0 + t1)) + (imgsz, imgsz, batch_size)  # tuple\n",
    "    if not training:\n",
    "        print('Speed: %.1f/%.1f/%.1f ms inference/NMS/total per %gx%g image at batch-size %g' % t)\n",
    "\n",
    "\n",
    "eval (model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Pytorch TRT Quantization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_quantization import nn as quant_nn\n",
    "from pytorch_quantization import calib\n",
    "from pytorch_quantization.tensor_quant import QuantDescriptor\n",
    "\n",
    "from absl import logging\n",
    "logging.set_verbosity(logging.INFO)  # Disable logging as they are too noisy in notebook\n",
    "\n",
    "quant_desc_input = QuantDescriptor(calib_method='histogram')\n",
    "quant_nn.QuantConv2d.set_default_quant_desc_input(quant_desc_input)\n",
    "quant_nn.QuantLinear.set_default_quant_desc_input(quant_desc_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_quantization import quant_modules\n",
    "quant_modules.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print (model)\n",
    "out1, out2 = model(torch.zeros(1, 3, 352, 672).to(device).type_as(next(model.parameters())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibration Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_stats(model, data_loader, num_batches):\n",
    "    \"\"\"Feed data to the network and collect statistic\"\"\"\n",
    "\n",
    "    # Enable calibrators\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, quant_nn.TensorQuantizer):\n",
    "            if module._calibrator is not None:\n",
    "                module.disable_quant()\n",
    "                module.enable_calib()\n",
    "            else:\n",
    "                module.disable()\n",
    "\n",
    "    # for i, (image, _) in tqdm(enumerate(data_loader), total=num_batches):\n",
    "    #     model(image.cuda())\n",
    "    #     if i >= num_batches:\n",
    "    #         break\n",
    "    for i, (img, _, _, _) in tqdm(enumerate(data_loader), total=num_batches):\n",
    "        img = img.to(device, non_blocking=True)\n",
    "        img =  img.float()  # uint8 to fp16/32\n",
    "        img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
    "        model(img, augment=augment)\n",
    "        if i >= num_batches:\n",
    "            break\n",
    "    \n",
    "\n",
    "    # Disable calibrators\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, quant_nn.TensorQuantizer):\n",
    "            if module._calibrator is not None:\n",
    "                module.enable_quant()\n",
    "                module.disable_calib()\n",
    "            else:\n",
    "                module.enable()\n",
    "            \n",
    "def compute_amax(model, **kwargs):\n",
    "    # Load calib result\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, quant_nn.TensorQuantizer):\n",
    "            if module._calibrator is not None:\n",
    "                if isinstance(module._calibrator, calib.MaxCalibrator):\n",
    "                    module.load_calib_amax()\n",
    "                else:\n",
    "                    module.load_calib_amax(**kwargs)\n",
    "#             print(F\"{name:40}: {module}\")\n",
    "    # model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Calibration Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': '/my_data/datasets/crowd_human_yolo_1000/train/images', 'val': '/my_data/datasets/crowd_human_yolo_1000/valid/images', 'nc': 2, 'names': ['person', 'head']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/my_data/datasets/crowd_human_yolo_1000/train/labels.cache' images and labels... 1000 found, 0 missing, 0 empty, 6 corrupted: 100%|| 1000/1000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "994"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if isinstance(data, str):\n",
    "    is_coco = data.endswith('coco.yaml')\n",
    "    with open(data) as f:\n",
    "        data = yaml.load(f, Loader=yaml.SafeLoader)\n",
    "check_dataset(data)  # check\n",
    "print (data)\n",
    "trt_calib_loader, trt_calib_dataset =  create_dataloader(data['train'], imgsz, batch_size, gs, opt, pad=0.5, rect=False,\n",
    "                                prefix=colorstr('train: '))\n",
    "\n",
    "len(trt_calib_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range (500): \n",
    "#     img, targets, paths, shapes  = next(iter(trt_calib_loader))\n",
    "#     print (img.shape)\n",
    "#     print (paths)\n",
    "\n",
    "# img, targets, paths, shapes  = next(iter(trt_calib_loader))\n",
    "# print (img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1203 21:12:08.212665 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.219638 140684794753408 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I1203 21:12:08.221172 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.222434 140684794753408 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I1203 21:12:08.224323 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.227807 140684794753408 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I1203 21:12:08.229250 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.235118 140684794753408 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I1203 21:12:08.236520 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.238334 140684794753408 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I1203 21:12:08.239295 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.243273 140684794753408 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I1203 21:12:08.244687 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.249286 140684794753408 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I1203 21:12:08.251721 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.253016 140684794753408 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I1203 21:12:08.254379 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.255705 140684794753408 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I1203 21:12:08.257827 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.259875 140684794753408 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I1203 21:12:08.263062 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.264543 140684794753408 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I1203 21:12:08.266515 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.267735 140684794753408 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I1203 21:12:08.268771 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.271770 140684794753408 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I1203 21:12:08.280472 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.282244 140684794753408 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I1203 21:12:08.283972 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.285140 140684794753408 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I1203 21:12:08.286334 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.287611 140684794753408 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I1203 21:12:08.288672 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.289803 140684794753408 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I1203 21:12:08.290948 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.293781 140684794753408 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I1203 21:12:08.294830 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.301177 140684794753408 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I1203 21:12:08.304008 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.305060 140684794753408 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I1203 21:12:08.306257 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.307244 140684794753408 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I1203 21:12:08.310148 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.315472 140684794753408 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I1203 21:12:08.316526 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.317409 140684794753408 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I1203 21:12:08.323711 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.324660 140684794753408 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I1203 21:12:08.325595 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.326499 140684794753408 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I1203 21:12:08.329872 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.331613 140684794753408 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I1203 21:12:08.334265 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.335121 140684794753408 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I1203 21:12:08.343865 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.345295 140684794753408 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I1203 21:12:08.346264 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.350110 140684794753408 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I1203 21:12:08.351544 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.352601 140684794753408 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I1203 21:12:08.353667 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.354634 140684794753408 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I1203 21:12:08.355569 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.356482 140684794753408 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I1203 21:12:08.357180 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.357877 140684794753408 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I1203 21:12:08.358673 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.359509 140684794753408 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I1203 21:12:08.360426 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.363526 140684794753408 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I1203 21:12:08.364410 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.370401 140684794753408 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I1203 21:12:08.371330 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.377506 140684794753408 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I1203 21:12:08.378306 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.379865 140684794753408 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I1203 21:12:08.380640 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.382400 140684794753408 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I1203 21:12:08.383194 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.383904 140684794753408 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I1203 21:12:08.389819 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.390657 140684794753408 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I1203 21:12:08.391373 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.392142 140684794753408 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I1203 21:12:08.393011 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.393834 140684794753408 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I1203 21:12:08.394610 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.395708 140684794753408 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I1203 21:12:08.396403 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.402325 140684794753408 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I1203 21:12:08.403106 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.403753 140684794753408 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I1203 21:12:08.404482 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.405228 140684794753408 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I1203 21:12:08.405948 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.406627 140684794753408 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I1203 21:12:08.407453 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.408156 140684794753408 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I1203 21:12:08.408953 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.414866 140684794753408 tensor_quantizer.py:179] Enable MaxCalibrator\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1203 21:12:08.415921 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.417652 140684794753408 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I1203 21:12:08.418421 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.419198 140684794753408 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I1203 21:12:08.419956 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.420791 140684794753408 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I1203 21:12:08.421563 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.422341 140684794753408 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I1203 21:12:08.428311 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.429331 140684794753408 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I1203 21:12:08.430347 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.431214 140684794753408 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I1203 21:12:08.431986 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.432747 140684794753408 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I1203 21:12:08.433471 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.434244 140684794753408 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I1203 21:12:08.435007 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.440956 140684794753408 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I1203 21:12:08.441853 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.442596 140684794753408 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I1203 21:12:08.443283 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.443954 140684794753408 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I1203 21:12:08.444734 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.445474 140684794753408 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I1203 21:12:08.447183 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.448071 140684794753408 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I1203 21:12:08.454278 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.455175 140684794753408 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I1203 21:12:08.455856 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.456499 140684794753408 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I1203 21:12:08.457108 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.457904 140684794753408 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I1203 21:12:08.458667 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.459739 140684794753408 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I1203 21:12:08.460471 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.466399 140684794753408 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I1203 21:12:08.467374 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.468165 140684794753408 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I1203 21:12:08.468972 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.469746 140684794753408 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I1203 21:12:08.470549 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.471273 140684794753408 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I1203 21:12:08.471975 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.472687 140684794753408 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I1203 21:12:08.475295 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.476173 140684794753408 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I1203 21:12:08.477000 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.499094 140684794753408 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I1203 21:12:08.500149 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.500965 140684794753408 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I1203 21:12:08.501701 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.502349 140684794753408 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I1203 21:12:08.503718 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.504776 140684794753408 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I1203 21:12:08.506215 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.507417 140684794753408 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I1203 21:12:08.508811 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.509608 140684794753408 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I1203 21:12:08.510544 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.515487 140684794753408 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I1203 21:12:08.516308 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.517375 140684794753408 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I1203 21:12:08.518127 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.519469 140684794753408 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I1203 21:12:08.520297 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.521069 140684794753408 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I1203 21:12:08.521799 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.523049 140684794753408 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I1203 21:12:08.524140 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.525547 140684794753408 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I1203 21:12:08.527061 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.528218 140684794753408 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I1203 21:12:08.528989 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.529738 140684794753408 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I1203 21:12:08.534598 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.535701 140684794753408 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I1203 21:12:08.536499 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.537810 140684794753408 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I1203 21:12:08.538825 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.541240 140684794753408 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I1203 21:12:08.543155 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.543992 140684794753408 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I1203 21:12:08.551455 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.552388 140684794753408 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I1203 21:12:08.553183 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.553942 140684794753408 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I1203 21:12:08.554676 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.555364 140684794753408 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I1203 21:12:08.556117 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.558685 140684794753408 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I1203 21:12:08.559878 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.560967 140684794753408 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I1203 21:12:08.579334 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.580945 140684794753408 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I1203 21:12:08.582885 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.585853 140684794753408 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I1203 21:12:08.599896 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.601265 140684794753408 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I1203 21:12:08.604024 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.608286 140684794753408 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I1203 21:12:08.613266 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.615761 140684794753408 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I1203 21:12:08.616484 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.617202 140684794753408 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I1203 21:12:08.617976 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.618718 140684794753408 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I1203 21:12:08.619969 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.620824 140684794753408 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I1203 21:12:08.623325 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.625342 140684794753408 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I1203 21:12:08.627230 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.628754 140684794753408 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I1203 21:12:08.633137 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.636043 140684794753408 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I1203 21:12:08.637426 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.640557 140684794753408 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "I1203 21:12:08.644822 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.646093 140684794753408 tensor_quantizer.py:179] Enable HistogramCalibrator\n",
      "I1203 21:12:08.646826 140684794753408 tensor_quantizer.py:183] Disable `quant` stage.\n",
      "I1203 21:12:08.648020 140684794753408 tensor_quantizer.py:179] Enable MaxCalibrator\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]I1203 21:12:08.813385 140684794753408 max.py:60] Calibrator encountered negative values. It shouldn't happen after ReLU. Make sure this is the right tensor to calibrate.\n",
      "I1203 21:12:08.866815 140684794753408 histogram.py:65] Calibrator encountered negative values. It shouldn't happen after ReLU. Make sure this is the right tensor to calibrate.\n",
      "100%|| 9/9 [00:21<00:00,  2.42s/it]\n",
      "I1203 21:12:30.396114 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.397227 140684794753408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I1203 21:12:30.399087 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.400319 140684794753408 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I1203 21:12:30.403046 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.404817 140684794753408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I1203 21:12:30.405706 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.406477 140684794753408 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I1203 21:12:30.407348 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.408762 140684794753408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I1203 21:12:30.409974 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.410999 140684794753408 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I1203 21:12:30.414237 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.415699 140684794753408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I1203 21:12:30.416913 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.417619 140684794753408 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I1203 21:12:30.418837 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.422089 140684794753408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I1203 21:12:30.425477 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.428034 140684794753408 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I1203 21:12:30.429031 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.430073 140684794753408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I1203 21:12:30.432020 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.433112 140684794753408 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I1203 21:12:30.434250 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.435589 140684794753408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I1203 21:12:30.436575 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.437355 140684794753408 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I1203 21:12:30.438259 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.439573 140684794753408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I1203 21:12:30.440580 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.441454 140684794753408 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I1203 21:12:30.442341 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.443280 140684794753408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I1203 21:12:30.444253 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.447439 140684794753408 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I1203 21:12:30.448511 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.449543 140684794753408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I1203 21:12:30.450865 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.452023 140684794753408 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I1203 21:12:30.455238 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.456191 140684794753408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I1203 21:12:30.457458 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.458439 140684794753408 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I1203 21:12:30.459423 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.460417 140684794753408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I1203 21:12:30.461340 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.462302 140684794753408 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I1203 21:12:30.463136 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.464088 140684794753408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I1203 21:12:30.465107 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.471730 140684794753408 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I1203 21:12:30.472659 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.473218 140684794753408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I1203 21:12:30.473845 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.474459 140684794753408 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I1203 21:12:30.475278 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.475860 140684794753408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I1203 21:12:30.476519 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.477126 140684794753408 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I1203 21:12:30.477795 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.478413 140684794753408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I1203 21:12:30.479125 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.479714 140684794753408 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I1203 21:12:30.480411 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.481009 140684794753408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I1203 21:12:30.481924 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.484004 140684794753408 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I1203 21:12:30.485046 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.486268 140684794753408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I1203 21:12:30.487503 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.489712 140684794753408 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I1203 21:12:30.491036 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.492208 140684794753408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I1203 21:12:30.493187 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.494174 140684794753408 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I1203 21:12:30.495131 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.495928 140684794753408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I1203 21:12:30.496709 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.497866 140684794753408 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I1203 21:12:30.498926 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.499826 140684794753408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I1203 21:12:30.500798 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.501665 140684794753408 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I1203 21:12:30.502676 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.503706 140684794753408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I1203 21:12:30.504706 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.505757 140684794753408 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I1203 21:12:30.513518 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.515289 140684794753408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I1203 21:12:30.516311 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.517300 140684794753408 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I1203 21:12:30.518211 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.519295 140684794753408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I1203 21:12:30.520264 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.521199 140684794753408 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I1203 21:12:30.522215 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.527035 140684794753408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I1203 21:12:30.534169 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.535031 140684794753408 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I1203 21:12:30.535732 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.542688 140684794753408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I1203 21:12:30.549328 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.560135 140684794753408 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I1203 21:12:30.560975 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.562131 140684794753408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I1203 21:12:30.563108 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.565629 140684794753408 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I1203 21:12:30.566555 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.567450 140684794753408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I1203 21:12:30.568246 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.569055 140684794753408 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I1203 21:12:30.572058 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.573183 140684794753408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I1203 21:12:30.574151 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.576623 140684794753408 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I1203 21:12:30.579212 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.593821 140684794753408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I1203 21:12:30.594819 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.595757 140684794753408 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I1203 21:12:30.596539 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.597338 140684794753408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I1203 21:12:30.598245 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.601278 140684794753408 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I1203 21:12:30.602404 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.607047 140684794753408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I1203 21:12:30.607888 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.608836 140684794753408 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I1203 21:12:30.610217 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.619589 140684794753408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I1203 21:12:30.620975 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.622931 140684794753408 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I1203 21:12:30.623883 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.625213 140684794753408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I1203 21:12:30.626499 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.629408 140684794753408 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I1203 21:12:30.630917 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.632851 140684794753408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I1203 21:12:30.633668 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.634636 140684794753408 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I1203 21:12:30.635621 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.636742 140684794753408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I1203 21:12:30.638542 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.640368 140684794753408 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I1203 21:12:30.641497 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.642444 140684794753408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I1203 21:12:30.644627 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.645839 140684794753408 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I1203 21:12:30.647053 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.648139 140684794753408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I1203 21:12:30.649101 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.650623 140684794753408 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I1203 21:12:30.656191 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.658079 140684794753408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I1203 21:12:30.659007 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.660239 140684794753408 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I1203 21:12:30.662380 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.665280 140684794753408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I1203 21:12:30.666313 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.667349 140684794753408 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I1203 21:12:30.668435 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.669927 140684794753408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I1203 21:12:30.675800 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.676841 140684794753408 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I1203 21:12:30.677843 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.678894 140684794753408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I1203 21:12:30.681509 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.682550 140684794753408 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I1203 21:12:30.683646 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.684728 140684794753408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I1203 21:12:30.685980 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.689320 140684794753408 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I1203 21:12:30.691457 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.693583 140684794753408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I1203 21:12:30.704022 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.707189 140684794753408 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I1203 21:12:30.710573 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.714792 140684794753408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I1203 21:12:30.718843 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.721660 140684794753408 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I1203 21:12:30.723261 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.725708 140684794753408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I1203 21:12:30.726446 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.727730 140684794753408 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I1203 21:12:30.728750 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.729692 140684794753408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I1203 21:12:30.732703 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.733583 140684794753408 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I1203 21:12:30.734366 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.735224 140684794753408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I1203 21:12:30.736137 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.737385 140684794753408 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I1203 21:12:30.738292 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.739149 140684794753408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I1203 21:12:30.740051 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.741173 140684794753408 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I1203 21:12:30.742340 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.743407 140684794753408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I1203 21:12:30.744295 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.745206 140684794753408 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I1203 21:12:30.746181 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.748148 140684794753408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I1203 21:12:30.749554 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.756202 140684794753408 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I1203 21:12:30.757128 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.757909 140684794753408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I1203 21:12:30.758895 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.759997 140684794753408 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I1203 21:12:30.761002 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.761869 140684794753408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I1203 21:12:30.762762 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.764671 140684794753408 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I1203 21:12:30.765553 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.766325 140684794753408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I1203 21:12:30.767258 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.768179 140684794753408 tensor_quantizer.py:173] Disable MaxCalibrator\n",
      "I1203 21:12:30.769150 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.770320 140684794753408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "I1203 21:12:30.771237 140684794753408 tensor_quantizer.py:187] Enable `quant` stage.\n",
      "W1203 21:12:30.772107 140684794753408 tensor_quantizer.py:173] Disable MaxCalibrator\n"
     ]
    }
   ],
   "source": [
    "num_batches = int(len(trt_calib_dataset)/batch_size)\n",
    "print (num_batches)\n",
    "\n",
    "with torch.no_grad():\n",
    "    collect_stats(model, trt_calib_loader, num_batches=9)\n",
    "    # compute_amax(detector.model, method=\"percentile\", percentile=99.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1203 21:13:38.451281 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W1203 21:13:38.452245 140684794753408 tensor_quantizer.py:238] Call .cuda() if running on GPU after loading calibrated amax.\n",
      "W1203 21:13:38.455153 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([32, 1, 1, 1]).\n",
      "W1203 21:13:38.459455 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W1203 21:13:38.465697 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W1203 21:13:38.467345 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W1203 21:13:38.468469 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([32, 1, 1, 1]).\n",
      "W1203 21:13:38.470915 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W1203 21:13:38.471800 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([32, 1, 1, 1]).\n",
      "W1203 21:13:38.473495 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W1203 21:13:38.474571 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([32, 1, 1, 1]).\n",
      "W1203 21:13:38.476222 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W1203 21:13:38.477037 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([32, 1, 1, 1]).\n",
      "W1203 21:13:38.478610 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W1203 21:13:38.479437 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W1203 21:13:38.481200 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W1203 21:13:38.482828 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W1203 21:13:38.486030 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W1203 21:13:38.486974 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W1203 21:13:38.488565 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W1203 21:13:38.489400 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W1203 21:13:38.491016 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W1203 21:13:38.492938 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W1203 21:13:38.494163 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W1203 21:13:38.497483 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([128, 1, 1, 1]).\n",
      "W1203 21:13:38.502912 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W1203 21:13:38.503787 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([128, 1, 1, 1]).\n",
      "W1203 21:13:38.505117 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W1203 21:13:38.506784 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([128, 1, 1, 1]).\n",
      "W1203 21:13:38.509163 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W1203 21:13:38.510179 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([128, 1, 1, 1]).\n",
      "W1203 21:13:38.511801 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W1203 21:13:38.518587 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([128, 1, 1, 1]).\n",
      "W1203 21:13:38.520343 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W1203 21:13:38.522130 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([256, 1, 1, 1]).\n",
      "W1203 21:13:38.524134 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W1203 21:13:38.524949 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([256, 1, 1, 1]).\n",
      "W1203 21:13:38.526506 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W1203 21:13:38.529020 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([256, 1, 1, 1]).\n",
      "W1203 21:13:38.535593 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W1203 21:13:38.536525 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([256, 1, 1, 1]).\n",
      "W1203 21:13:38.538672 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W1203 21:13:38.544847 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([256, 1, 1, 1]).\n",
      "W1203 21:13:38.550824 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W1203 21:13:38.551910 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([512, 1, 1, 1]).\n",
      "W1203 21:13:38.553523 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W1203 21:13:38.554337 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([256, 1, 1, 1]).\n",
      "W1203 21:13:38.555395 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W1203 21:13:38.556553 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([256, 1, 1, 1]).\n",
      "W1203 21:13:38.558153 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W1203 21:13:38.563243 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([256, 1, 1, 1]).\n",
      "W1203 21:13:38.566262 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W1203 21:13:38.567150 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([256, 1, 1, 1]).\n",
      "W1203 21:13:38.570722 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W1203 21:13:38.572607 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([128, 1, 1, 1]).\n",
      "W1203 21:13:38.573906 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W1203 21:13:38.577490 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([128, 1, 1, 1]).\n",
      "W1203 21:13:38.579552 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W1203 21:13:38.580368 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W1203 21:13:38.581948 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W1203 21:13:38.583885 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W1203 21:13:38.587020 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W1203 21:13:38.589401 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W1203 21:13:38.591402 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W1203 21:13:38.592711 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W1203 21:13:38.593864 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W1203 21:13:38.594982 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([128, 1, 1, 1]).\n",
      "W1203 21:13:38.599444 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W1203 21:13:38.601125 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W1203 21:13:38.602941 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W1203 21:13:38.604281 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W1203 21:13:38.619452 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W1203 21:13:38.620651 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([32, 1, 1, 1]).\n",
      "W1203 21:13:38.622595 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W1203 21:13:38.623945 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([32, 1, 1, 1]).\n",
      "W1203 21:13:38.628649 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W1203 21:13:38.630478 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([32, 1, 1, 1]).\n",
      "W1203 21:13:38.637843 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W1203 21:13:38.638808 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([32, 1, 1, 1]).\n",
      "W1203 21:13:38.640782 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W1203 21:13:38.642266 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W1203 21:13:38.645375 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ############  percentile calibration ######################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1203 21:13:38.653696 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([128, 1, 1, 1]).\n",
      "W1203 21:13:38.656292 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W1203 21:13:38.657249 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W1203 21:13:38.659252 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W1203 21:13:38.660947 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W1203 21:13:38.667715 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W1203 21:13:38.670453 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W1203 21:13:38.671937 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W1203 21:13:38.676986 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W1203 21:13:38.678791 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W1203 21:13:38.687150 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([128, 1, 1, 1]).\n",
      "W1203 21:13:38.688765 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W1203 21:13:38.689763 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([256, 1, 1, 1]).\n",
      "W1203 21:13:38.691634 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W1203 21:13:38.692674 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([128, 1, 1, 1]).\n",
      "W1203 21:13:38.694640 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W1203 21:13:38.695731 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([128, 1, 1, 1]).\n",
      "W1203 21:13:38.697715 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W1203 21:13:38.698651 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([128, 1, 1, 1]).\n",
      "W1203 21:13:38.702346 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W1203 21:13:38.703408 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([128, 1, 1, 1]).\n",
      "W1203 21:13:38.705272 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W1203 21:13:38.709793 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([256, 1, 1, 1]).\n",
      "W1203 21:13:38.711990 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W1203 21:13:38.712990 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([128, 1, 1, 1]).\n",
      "W1203 21:13:38.714793 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W1203 21:13:38.715880 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([256, 1, 1, 1]).\n",
      "W1203 21:13:38.717190 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W1203 21:13:38.719859 140684794753408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([512, 1, 1, 1]).\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    # for method in [\"percentile\", \"mse\", \"entropy\"]:\n",
    "    for method in [ \"mse\",\"percentile\", \"entropy\"]:\n",
    "        percentile = 99.99\n",
    "        print(F\" ############  {method} calibration ######################\")\n",
    "        if(method == 'percentile'):\n",
    "            compute_amax(model, method=method, percentile = percentile)\n",
    "        else:\n",
    "            compute_amax(model, method=method)\n",
    "        \n",
    "        \n",
    "        eval(model)\n",
    "        torch.save(model.state_dict(), f\"tiny_yolo_v7_ch_{method}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_nn.TensorQuantizer.use_fb_fake_quant = True\n",
    "dummy_input = torch.randn(1, 3, 640, 640, device=device)\n",
    "\n",
    "\n",
    "# enable_onnx_checker needs to be disabled. See notes below.\n",
    "torch.onnx.export(\n",
    "    model, dummy_input, \"a.onnx\", verbose=True, opset_version=13, enable_onnx_checker=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare speed of FP32 vs INT8 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import onnxruntime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def benchmark(model_path):\n",
    "    session = onnxruntime.InferenceSession(model_path)\n",
    "    input_name = session.get_inputs()[0].name\n",
    "\n",
    "    total = 0.0\n",
    "    runs = 10\n",
    "    input_data = np.zeros((1, 3, 640, 640), np.float32)\n",
    "    # Warming up\n",
    "    _ = session.run([], {input_name: input_data})\n",
    "    for i in range(runs):\n",
    "        start = time.perf_counter()\n",
    "        _ = session.run([], {input_name: input_data})\n",
    "        end = (time.perf_counter() - start) * 1000\n",
    "        total += end\n",
    "        print(f\"{end:.2f}ms\")\n",
    "    total /= runs\n",
    "    print(f\"Avg: {total:.2f}ms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benchmarking fp32 model...\n",
      "192.95ms\n",
      "187.73ms\n",
      "192.39ms\n",
      "188.09ms\n",
      "162.90ms\n",
      "149.94ms\n",
      "151.48ms\n",
      "157.76ms\n",
      "172.81ms\n",
      "175.87ms\n",
      "Avg: 173.19ms\n",
      "benchmarking int8 model...\n",
      "299.21ms\n",
      "284.16ms\n",
      "220.35ms\n",
      "182.48ms\n",
      "316.36ms\n",
      "339.97ms\n",
      "202.65ms\n",
      "207.60ms\n",
      "218.38ms\n",
      "234.06ms\n",
      "Avg: 250.52ms\n"
     ]
    }
   ],
   "source": [
    "fp32_model_path = '/home/gjraza/aletheia_ai/interview_task/yolov7/runs_colab/train/yolov7-tiny-crowd-human-1000-2/weights/best.onnx'\n",
    "int8_model_path =  \"yolov7-tiny-ch-int8.onnx\"\n",
    "print(\"benchmarking fp32 model...\")\n",
    "benchmark(fp32_model_path)\n",
    "\n",
    "print(\"benchmarking int8 model...\")\n",
    "benchmark(int8_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking Quantized ONNX Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = onnxruntime.InferenceSession(int8_model_path)\n",
    "input_name = session.get_inputs()[0].name\n",
    "\n",
    "output_names  = session.get_outputs()\n",
    "# for name in output_names:\n",
    "#     print(name.name)\n",
    "#     print(name.shape)\n",
    "\n",
    "# print (input_name)\n",
    "\n",
    "# outs = session.run([], {input_name: input_data})\n",
    "# print (outs[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "tensor([0.50000, 0.55000, 0.60000, 0.65000, 0.70000, 0.75000, 0.80000, 0.85000, 0.90000, 0.95000])\n",
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/my_data/datasets/crowd_human_yolo_1000/valid/labels.cache' images and labels... 200 found, 0 missing, 0 empty, 0 corrupted: 100%|| 200/200 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "names:\n",
      " {0: 'person', 1: 'head'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100%|| 200/200 [00:50<00:00,  3.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         200        8622         0.8       0.613       0.675       0.341\n",
      "              person         200        4311       0.809       0.661       0.735        0.39\n",
      "                head         200        4311       0.792       0.564       0.615       0.292\n",
      "Speed: 203.4/4.1/207.4 ms inference/NMS/total per 640x640 image at batch-size 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if isinstance(data, str):\n",
    "    is_coco = data.endswith('coco.yaml')\n",
    "    with open(data) as f:\n",
    "        data = yaml.load(f, Loader=yaml.SafeLoader)\n",
    "check_dataset(data)  # check\n",
    "nc = 1 if single_cls else int(data['nc'])  # number of classes\n",
    "iouv = torch.linspace(0.5, 0.95, 10).to(device)  # iou vector for mAP@0.5:0.95\n",
    "niou = iouv.numel()\n",
    "print (nc)\n",
    "print (iouv)\n",
    "print (niou)\n",
    "# Dataloader\n",
    "\n",
    "if device != 'cpu':\n",
    "    model(torch.zeros(1, 3, imgsz, imgsz).to(device).type_as(next(model.parameters())))  # run once\n",
    "task = 'val'  # path to train/val/test images\n",
    "dataloader = create_dataloader(data[task], imgsz, batch_size, gs, opt, pad=0.5, rect=False,\n",
    "                                prefix=colorstr(f'{task}: '))[0]\n",
    "\n",
    "\n",
    "seen = 0\n",
    "confusion_matrix = ConfusionMatrix(nc=nc)\n",
    "names = {k: v for k, v in enumerate(model.names if hasattr(model, 'names') else model.module.names)}\n",
    "print ('names:\\n', names)\n",
    "coco91class = coco80_to_coco91_class()\n",
    "s = ('%20s' + '%12s' * 6) % ('Class', 'Images', 'Labels', 'P', 'R', 'mAP@.5', 'mAP@.5:.95')\n",
    "p, r, f1, mp, mr, map50, map, t0, t1 = 0., 0., 0., 0., 0., 0., 0., 0., 0.\n",
    "loss = torch.zeros(3, device=device)\n",
    "jdict, stats, ap, ap_class, wandb_images = [], [], [], [], []\n",
    "\n",
    "\n",
    "for batch_i, (img, targets, paths, shapes) in enumerate(tqdm(dataloader, desc=s)):\n",
    "        img = img.to(device, non_blocking=True)\n",
    "        img =  img.float()  # uint8 to fp16/32\n",
    "        img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
    "        targets = targets.to(device)\n",
    "        nb, _, height, width = img.shape  # batch size, channels, height, width\n",
    "        # print (img.shape)\n",
    "        with torch.no_grad():\n",
    "            # Run model\n",
    "            t = time_synchronized()\n",
    "            # out, train_out = model(img, augment=augment)  # inference and training outputs\n",
    "            out = session.run([], {input_name: img.numpy()})\n",
    "            out = torch.from_numpy(out[0]) \n",
    "            t0 += time_synchronized() - t\n",
    "\n",
    "            # # Compute loss\n",
    "            # if compute_loss:\n",
    "            #     loss += compute_loss([x.float() for x in train_out], targets)[1][:3]  # box, obj, cls\n",
    "\n",
    "            # Run NMS\n",
    "            targets[:, 2:] *= torch.Tensor([width, height, width, height]).to(device)  # to pixels\n",
    "            lb = [targets[targets[:, 0] == i, 1:] for i in range(nb)] if save_hybrid else []  # for autolabelling\n",
    "            t = time_synchronized()\n",
    "            out = non_max_suppression(out, conf_thres=conf_thres, iou_thres=iou_thres, labels=lb, multi_label=True)\n",
    "            t1 += time_synchronized() - t\n",
    "\n",
    "        # Statistics per image\n",
    "        for si, pred in enumerate(out):\n",
    "            labels = targets[targets[:, 0] == si, 1:]\n",
    "            nl = len(labels)\n",
    "            tcls = labels[:, 0].tolist() if nl else []  # target class\n",
    "            path = Path(paths[si])\n",
    "            seen += 1\n",
    "\n",
    "            if len(pred) == 0:\n",
    "                if nl:\n",
    "                    stats.append((torch.zeros(0, niou, dtype=torch.bool), torch.Tensor(), torch.Tensor(), tcls))\n",
    "                continue\n",
    "\n",
    "            # Predictions\n",
    "            predn = pred.clone()\n",
    "            scale_coords(img[si].shape[1:], predn[:, :4], shapes[si][0], shapes[si][1])  # native-space pred\n",
    "\n",
    "\n",
    "            # Assign all predictions as incorrect\n",
    "            correct = torch.zeros(pred.shape[0], niou, dtype=torch.bool, device=device)\n",
    "            if nl:\n",
    "                detected = []  # target indices\n",
    "                tcls_tensor = labels[:, 0]\n",
    "\n",
    "                # target boxes\n",
    "                tbox = xywh2xyxy(labels[:, 1:5])\n",
    "                scale_coords(img[si].shape[1:], tbox, shapes[si][0], shapes[si][1])  # native-space labels\n",
    "\n",
    "                # Per target class\n",
    "                for cls in torch.unique(tcls_tensor):\n",
    "                    ti = (cls == tcls_tensor).nonzero(as_tuple=False).view(-1)  # prediction indices\n",
    "                    pi = (cls == pred[:, 5]).nonzero(as_tuple=False).view(-1)  # target indices\n",
    "\n",
    "                    # Search for detections\n",
    "                    if pi.shape[0]:\n",
    "                        # Prediction to target ious\n",
    "                        ious, i = box_iou(predn[pi, :4], tbox[ti]).max(1)  # best ious, indices\n",
    "\n",
    "                        # Append detections\n",
    "                        detected_set = set()\n",
    "                        for j in (ious > iouv[0]).nonzero(as_tuple=False):\n",
    "                            d = ti[i[j]]  # detected target\n",
    "                            if d.item() not in detected_set:\n",
    "                                detected_set.add(d.item())\n",
    "                                detected.append(d)\n",
    "                                correct[pi[j]] = ious[j] > iouv  # iou_thres is 1xn\n",
    "                                if len(detected) == nl:  # all targets already located in image\n",
    "                                    break\n",
    "\n",
    "            # Append statistics (correct, conf, pcls, tcls)\n",
    "            stats.append((correct.cpu(), pred[:, 4].cpu(), pred[:, 5].cpu(), tcls))\n",
    "\n",
    "\n",
    "# Compute statistics\n",
    "stats = [np.concatenate(x, 0) for x in zip(*stats)]  # to numpy\n",
    "if len(stats) and stats[0].any():\n",
    "    p, r, ap, f1, ap_class = ap_per_class(*stats, plot=False, v5_metric=False, save_dir=save_dir, names=names)\n",
    "    ap50, ap = ap[:, 0], ap.mean(1)  # AP@0.5, AP@0.5:0.95\n",
    "    mp, mr, map50, map = p.mean(), r.mean(), ap50.mean(), ap.mean()\n",
    "    nt = np.bincount(stats[3].astype(np.int64), minlength=nc)  # number of targets per class\n",
    "else:\n",
    "    nt = torch.zeros(1)\n",
    "\n",
    "# Print results\n",
    "pf = '%20s' + '%12i' * 2 + '%12.3g' * 4  # print format\n",
    "print(pf % ('all', seen, nt.sum(), mp, mr, map50, map))\n",
    "\n",
    "# Print results per class\n",
    "if (verbose or (nc < 50 and not training)) and nc > 1 and len(stats):\n",
    "    for i, c in enumerate(ap_class):\n",
    "        print(pf % (names[c], seen, nt[c], p[i], r[i], ap50[i], ap[i]))\n",
    "\n",
    "# Print speeds\n",
    "t = tuple(x / seen * 1E3 for x in (t0, t1, t0 + t1)) + (imgsz, imgsz, batch_size)  # tuple\n",
    "if not training:\n",
    "    print('Speed: %.1f/%.1f/%.1f ms inference/NMS/total per %gx%g image at batch-size %g' % t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('yolov7-pt-quant')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a153251ca918835180584c03bace5927b30b0ca6b4e5db663f01f838abd98e72"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
