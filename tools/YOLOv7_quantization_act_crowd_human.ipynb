{"cells":[{"cell_type":"markdown","metadata":{"id":"w4YJEjTUIh7k"},"source":["# YOLOv7 Quantization Compression Example\n","\n","This example uses [ACT](https://github.com/PaddlePaddle/PaddleSlim/tree/develop/example/auto_compression) from [PaddleSlim](https://github.com/PaddlePaddle/PaddleSlim) for YOLOv7 quantization.\n","The quantized model can be deployed on TensorRT.\n","\n","- Benchmark\n","\n","| Model | Base mAP<sup>val<br>0.5:0.95  | Quant mAP<sup>val<br>0.5:0.95 | Latency<sup><small>FP32</small><sup><br><sup> | Latency<sup><small>FP16</small><sup><br><sup> | Latency<sup><small>INT8</small><sup><br><sup> | Model |\n","| :-------- |:-------- |:--------: | :--------: | :---------------------: | :----------------: | :----------------: |\n","| YOLOv7 |  51.2   | 50.9  |  26.84ms  |   7.44ms   |  **4.55ms**  | [ONNX](https://paddle-slim-models.bj.bcebos.com/act/yolov7.onnx) &#124; [Quant ONNX](https://bj.bcebos.com/v1/paddle-slim-models/act/yolov7_quant_onnx.tar) |\n","| YOLOv7-Tiny  |  37.3   | 37.0 |  5.06ms  |   2.32ms   |  **1.68ms** | [ONNX](https://paddle-slim-models.bj.bcebos.com/act/yolov7-tiny.onnx) &#124; [Quant ONNX](https://bj.bcebos.com/v1/paddle-slim-models/act/yolov7_tiny_quant_onnx.tar) |"]},{"cell_type":"markdown","metadata":{"id":"QX9JrDP3Ih70"},"source":["### Experiment\n","\n","(1) Environment Dependencies Installation:\n","  - paddlepaddle>=2.3.2\n","  - paddleslim>=2.3.4\n","  - pycocotools"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":384,"status":"ok","timestamp":1669464191202,"user":{"displayName":"Ghulam Jilani Raza","userId":"17365019358853388624"},"user_tz":-300},"id":"havF9dNJIxUH","outputId":"67d5ddcd-da9e-4cec-ab34-5580c59f658e"},"outputs":[{"name":"stdout","output_type":"stream","text":["hello\n"]}],"source":["print ('hello')\n","# !nvidia-smi"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30815,"status":"ok","timestamp":1669464062642,"user":{"displayName":"Ghulam Jilani Raza","userId":"17365019358853388624"},"user_tz":-300},"id":"wxCaqQ6PyEIy","outputId":"8e973f27-9255-48c9-80aa-6778b718178a"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5836,"status":"ok","timestamp":1669465384286,"user":{"displayName":"Ghulam Jilani Raza","userId":"17365019358853388624"},"user_tz":-300},"id":"Ux7pUu3EIh75","outputId":"6a04959d-e152-4e56-8320-e90ab510d85c"},"outputs":[],"source":["# Take Ubuntu and CUDA 11.2 as an example for GPU, and other environments can be installed directly according to Paddle's official website.\n","#  https://www.paddlepaddle.org.cn/install/quick?docurl=/documentation/docs/zh/install/pip/linux-pip.html \n","\n","# python -m pip install paddlepaddle-gpu==2.3.2.post112 -f https://www.paddlepaddle.org.cn/whl/linux/mkl/avx/stable.html\n","# !pip3 install paddlepaddle-gpu==2.3.2.post112 paddleslim==2.3.4 x2paddle==1.3.8 -f https://www.paddlepaddle.org.cn/whl/linux/mkl/avx/stable.html\n","\n","# CPU\n","#pip install paddlepaddle==2.3.2\n","\n","# !pip3 install paddleslim==2.3.4"]},{"cell_type":"markdown","metadata":{"id":"xR-5wWWMIh7-"},"source":["(2) Model Preparation: the YOLOv7 ONNX model (currently only exclude NMS are supported)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"22WM-bTXIh8B"},"outputs":[],"source":["# export yolov7-tiny.onnx\n","# !git clone https://github.com/WongKinYiu/yolov7\n","# %cd yolov7\n","# !wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-tiny.pt\n","# !python export.py --weights yolov7-tiny.pt --grid\n","\n","# Can also directly download the exported ONNX model\n","# !wget https://paddle-slim-models.bj.bcebos.com/act/yolov7-tiny.onnx"]},{"cell_type":"markdown","metadata":{"id":"tYj8QOXYIh8D"},"source":["(3) Dataset Preparation (some unlabeled pictures of real scenes):\n","\n","The directory format is as follows:\n","```\n","image_dir\n","├── 000000000139.jpg\n","├── 000000000285.jpg\n","├── ...\n","```\n","\n","We use COCO's official `val` set as the image path."]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":515,"status":"ok","timestamp":1669465413858,"user":{"displayName":"Ghulam Jilani Raza","userId":"17365019358853388624"},"user_tz":-300},"id":"8XPcVVbuIh8V"},"outputs":[],"source":["# image_dir' = './dataset/coco/val2017/'\n","# model_dir = './yolov7-tiny.onnx'\n","\n","# image_dir = '/content/drive/MyDrive/Colab_Notebooks/data/crowd_human_yolo_1000/train'\n","# model_dir = '/content/drive/MyDrive/Colab_Notebooks/yolov7/runs/train/yolov7-tiny-crowd-human-1000-2/weights/best.onnx'\n","\n","image_dir = '/my_data/datasets/crowd_human_yolo_100/train'\n","model_dir = '/home/gjraza/aletheia_ai/interview_task/yolov7/runs_colab/train/yolov7-tiny-crowd-human-1000-2/weights/best.onnx'\n"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":48,"status":"ok","timestamp":1669465414501,"user":{"displayName":"Ghulam Jilani Raza","userId":"17365019358853388624"},"user_tz":-300},"id":"IiB3WVFIVrWw"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"tsTnwIYXIh8X"},"source":["(4) Dependency Packages Import:"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1880,"status":"ok","timestamp":1669465419653,"user":{"displayName":"Ghulam Jilani Raza","userId":"17365019358853388624"},"user_tz":-300},"id":"qWc9cHmBIh8Z","outputId":"552f2092-a959-4916-c6b6-2b25f694ab4c"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/gjraza/miniconda3/envs/yolov7/lib/python3.8/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n","  warnings.warn(\"Setuptools is replacing distutils.\")\n"]},{"data":{"text/plain":["Place(cpu)"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["import cv2\n","import os\n","import numpy as np\n","import sys\n","# os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n","import paddle\n","from paddleslim.auto_compression import AutoCompression\n","\n","paddle.set_device('cpu')"]},{"cell_type":"markdown","metadata":{"id":"P4oJodVaIh8d"},"source":["(5) Definition of Data Preprocessing:"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1669465419654,"user":{"displayName":"Ghulam Jilani Raza","userId":"17365019358853388624"},"user_tz":-300},"id":"UFPMyvXgIh8e"},"outputs":[],"source":["def _generate_scale(im, target_shape, keep_ratio=True):\n","    origin_shape = im.shape[:2]\n","    im_size_min = np.min(origin_shape)\n","    im_size_max = np.max(origin_shape)\n","    target_size_min = np.min(target_shape)\n","    target_size_max = np.max(target_shape)\n","    im_scale = float(target_size_min) / float(im_size_min)\n","    if np.round(im_scale * im_size_max) > target_size_max:\n","        im_scale = float(target_size_max) / float(im_size_max)\n","    im_scale_x = im_scale\n","    im_scale_y = im_scale\n","    return im_scale_y, im_scale_x\n","\n","def image_preprocess(img, target_shape=[640,640]):\n","    # Resize image\n","    im_scale_y, im_scale_x = _generate_scale(img, target_shape)\n","    img = cv2.resize(\n","        img,\n","        None,\n","        None,\n","        fx=im_scale_x,\n","        fy=im_scale_y,\n","        interpolation=cv2.INTER_LINEAR)\n","    # Pad\n","    im_h, im_w = img.shape[:2]\n","    h, w = target_shape[:]\n","    if h != im_h or w != im_w:\n","        canvas = np.ones((h, w, 3), dtype=np.float32)\n","        canvas *= np.array([114.0, 114.0, 114.0], dtype=np.float32)\n","        canvas[0:im_h, 0:im_w, :] = img.astype(np.float32)\n","        img = canvas\n","    img = np.transpose(img / 255, [2, 0, 1])\n","    return img.astype(np.float32)"]},{"cell_type":"markdown","metadata":{"id":"xhvsMmqoIh8h"},"source":["(6) Definition of Configuration for AutoCompression:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["all_cofig: \n"," {'Global': {'model_dir': '/home/gjraza/aletheia_ai/interview_task/PaddleSlim/experiments/best.onnx', 'image_path': 'None', 'coco_dataset_dir': '/my_data/datasets/crowd_human_1000_v2i_coco', 'coco_train_image_dir': 'train', 'coco_train_anno_path': 'annotations/train_annotations.coco.json', 'coco_val_image_dir': 'valid', 'coco_val_anno_path': 'annotations/valid_annotations.coco.json', 'arch': 'YOLOv7'}, 'Distillation': {'alpha': 1.0, 'loss': 'soft_label'}, 'QuantAware': {'onnx_format': True, 'activation_quantize_type': 'moving_average_abs_max', 'quantize_op_types': ['conv2d', 'depthwise_conv2d']}, 'TrainConfig': {'train_iter': 2, 'eval_iter': 1, 'learning_rate': {'type': 'CosineAnnealingDecay', 'learning_rate': 3e-05, 'T_max': 8000}, 'optimizer_builder': {'optimizer': {'type': 'SGD'}, 'weight_decay': 4e-05}}}"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1669465869691,"user":{"displayName":"Ghulam Jilani Raza","userId":"17365019358853388624"},"user_tz":-300},"id":"Md3atVtrIh8h","outputId":"4d8e46a1-401e-420a-ea65-76b4d66ce5cd"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'Quantization': {'onnx_format': True, 'activation_quantize_type': 'moving_average_abs_max', 'quantize_op_types': ['conv2d', 'depthwise_conv2d']}}\n"]}],"source":["# run_config = {\n","#     'Distillation': {\n","#         'alpha': 1.0,\n","#         'loss': 'soft_label'},\n","#     'Quantization': {\n","#         'onnx_format': True,\n","#         'activation_quantize_type': 'moving_average_abs_max',\n","#         'quantize_op_types': ['conv2d', 'depthwise_conv2d']},\n","#     'TrainConfig': {\n","#         'train_iter': 5,\n","#         'eval_iter': 1,\n","#         'learning_rate': 0.00003,\n","#         'optimizer_builder': {'optimizer': {'type': 'SGD'}, 'weight_decay': 4e-05}}\n","# }\n","\n","run_config = {\n","    \n","    'Quantization': {\n","        'onnx_format': True,\n","        'activation_quantize_type': 'moving_average_abs_max',\n","        'quantize_op_types': ['conv2d', 'depthwise_conv2d']}\n","}\n","\n","\n","\n","# run_config = {\n","#     'Distillation': {\n","#         'alpha': 1.0,\n","#         'loss': 'soft_label'},\n","#     'TrainConfig': {\n","#         'train_iter': 5,\n","#         'eval_iter': 1,\n","#         'learning_rate': 0.00003,\n","#         'optimizer_builder': {'optimizer': {'type': 'SGD'}, 'weight_decay': 4e-05}}\n","# }\n","\n","# run_config = {\n","#     'Distillation': {\n","#         'alpha': 1.0,\n","#         'loss': 'soft_label'}\n","# }\n","\n","print (run_config)"]},{"cell_type":"markdown","metadata":{"id":"8EzYNK_mIh8j"},"source":["(7) Auto Compression:"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":171371,"status":"ok","timestamp":1669466094791,"user":{"displayName":"Ghulam Jilani Raza","userId":"17365019358853388624"},"user_tz":-300},"id":"YBZeLSKpIh8j","outputId":"0a457206-f988-4648-b493-63c203c1708c"},"outputs":[{"ename":"AssertionError","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn [17], line 19\u001b[0m\n\u001b[1;32m     12\u001b[0m save_dir\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/home/gjraza/aletheia_ai/interview_task/yolov7/runs_colab/train/yolov7-tiny-crowd-human-1000-2/weights/ac_output_5\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     13\u001b[0m ac \u001b[39m=\u001b[39m AutoCompression(\n\u001b[1;32m     14\u001b[0m     model_dir\u001b[39m=\u001b[39mmodel_dir,\n\u001b[1;32m     15\u001b[0m     train_dataloader\u001b[39m=\u001b[39mreader_wrapper(train_loader),\n\u001b[1;32m     16\u001b[0m     save_dir\u001b[39m=\u001b[39msave_dir,\n\u001b[1;32m     17\u001b[0m     config\u001b[39m=\u001b[39mrun_config,\n\u001b[1;32m     18\u001b[0m     eval_callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[0;32m---> 19\u001b[0m ac\u001b[39m.\u001b[39;49mcompress()\n\u001b[1;32m     20\u001b[0m \u001b[39m# convert to ONNX\u001b[39;00m\n\u001b[1;32m     21\u001b[0m ac\u001b[39m.\u001b[39mexport_onnx()\n","File \u001b[0;32m~/miniconda3/envs/yolov7/lib/python3.8/site-packages/paddleslim/auto_compression/compressor.py:559\u001b[0m, in \u001b[0;36mAutoCompression.compress\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompress\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 559\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_strategy) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    560\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtmp_dir \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_tmp_dir(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinal_dir)\n\u001b[1;32m    561\u001b[0m     strategy \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n","\u001b[0;31mAssertionError\u001b[0m: "]},{"name":"stderr","output_type":"stream","text":["2022-11-27 18:43:48,767-INFO: Loaded model from: /home/gjraza/aletheia_ai/interview_task/yolov7/runs_colab/train/yolov7-tiny-crowd-human-1000-2/weights/best_infer\n","2022-11-27 18:43:49,171-INFO: devices: cpu\n","2022-11-27 18:43:49,457-INFO: Loaded model from: /home/gjraza/aletheia_ai/interview_task/yolov7/runs_colab/train/yolov7-tiny-crowd-human-1000-2/weights/best_infer\n","2022-11-27 18:43:50,648-INFO: Detect model type: None\n","2022-11-27 18:43:50,821-INFO: Loaded model from: /home/gjraza/aletheia_ai/interview_task/yolov7/runs_colab/train/yolov7-tiny-crowd-human-1000-2/weights/best_infer\n","2022-11-27 18:43:50,827-INFO: Selected strategies: []\n"]},{"ename":"AssertionError","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn [19], line 19\u001b[0m\n\u001b[1;32m     12\u001b[0m save_dir\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/home/gjraza/aletheia_ai/interview_task/yolov7/runs_colab/train/yolov7-tiny-crowd-human-1000-2/weights/ac_output_6\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     13\u001b[0m ac \u001b[39m=\u001b[39m AutoCompression(\n\u001b[1;32m     14\u001b[0m     model_dir\u001b[39m=\u001b[39mmodel_dir,\n\u001b[1;32m     15\u001b[0m     train_dataloader\u001b[39m=\u001b[39mreader_wrapper(train_loader),\n\u001b[1;32m     16\u001b[0m     save_dir\u001b[39m=\u001b[39msave_dir,\n\u001b[1;32m     17\u001b[0m     config\u001b[39m=\u001b[39mrun_config,\n\u001b[1;32m     18\u001b[0m     eval_callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[0;32m---> 19\u001b[0m ac\u001b[39m.\u001b[39;49mcompress()\n\u001b[1;32m     20\u001b[0m \u001b[39m# convert to ONNX\u001b[39;00m\n\u001b[1;32m     21\u001b[0m ac\u001b[39m.\u001b[39mexport_onnx()\n","File \u001b[0;32m~/miniconda3/envs/yolov7/lib/python3.8/site-packages/paddleslim/auto_compression/compressor.py:559\u001b[0m, in \u001b[0;36mAutoCompression.compress\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompress\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 559\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_strategy) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    560\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtmp_dir \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_tmp_dir(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinal_dir)\n\u001b[1;32m    561\u001b[0m     strategy \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n","\u001b[0;31mAssertionError\u001b[0m: "]}],"source":["%tb\n","def reader_wrapper(reader, input_name='x2paddle_images'):\n","    def gen():\n","        for data in reader:\n","            yield {input_name: data[0]}\n","    return gen\n","\n","paddle.vision.image.set_image_backend('cv2')\n","train_dataset = paddle.vision.datasets.ImageFolder(image_dir, transform=image_preprocess)\n","train_loader = paddle.io.DataLoader(train_dataset, batch_size=1, shuffle=True, drop_last=True, num_workers=0)\n","\n","save_dir='/home/gjraza/aletheia_ai/interview_task/yolov7/runs_colab/train/yolov7-tiny-crowd-human-1000-2/weights/ac_output_6'\n","ac = AutoCompression(\n","    model_dir=model_dir,\n","    train_dataloader=reader_wrapper(train_loader),\n","    save_dir=save_dir,\n","    config=run_config,\n","    eval_callback=None)\n","ac.compress()\n","# convert to ONNX\n","ac.export_onnx()"]},{"cell_type":"markdown","metadata":{"id":"-bfuNoKcIh8n"},"source":["### After executing the program, output files will be generated in the output folder as shown below:\n","\n","```shell\n","├── model.pdiparams         # Paddle predicts model weights\n","├── model.pdmodel           # Paddle prediction model file\n","├── calibration_table.txt   # Paddle calibration table after quantification\n","├── ONNX\n","│   ├── quant_model.onnx      # ONNX model after quantization\n","│   ├── calibration.cache     # TensorRT can directly load the calibration table\n","```\n","\n","- Speed Test:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7UXOX4hwIh8o"},"outputs":[],"source":["trtexec --onnx=output/ONNX/quant_model.onnx --avgRuns=1000 --workspace=1024 --calib=output/ONNX/calibration.cache --int8"]},{"cell_type":"markdown","metadata":{"id":"CJpkvI_tIh8q"},"source":["- Python test:\n","Load `quant_model.onnx` and `calibration.cache`, you can directly use the TensorRT test script to verify. The detailed code can refer to [TensorRT deployment](/TensorRT).\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MS_ppCFdIh8r"},"outputs":[],"source":["!git clone https://github.com/PaddlePaddle/PaddleSlim.git\n","!cd example/auto_compression/pytorch_yolo_series/TensorRT\n","python trt_eval.py --onnx_model_file=output/ONNX/quant_model.onnx \\\n","                   --calibration_file=output/ONNX/calibration.cache \\\n","                   --image_file=../images/000000570688.jpg \\\n","                   --precision_mode=int8"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1669466506510,"user":{"displayName":"Ghulam Jilani Raza","userId":"17365019358853388624"},"user_tz":-300},"id":"0IEdGral9Gn5","outputId":"d3ee7466-289d-42af-d2c7-235cca674acb"},"outputs":[{"name":"stdout","output_type":"stream","text":["/bin/bash: docker: command not found\n"]}],"source":["!docker -v"]},{"cell_type":"markdown","metadata":{"id":"_1He-u4zIh8s"},"source":["And you can also eval COCO mAP:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6tasjym9Ih8s"},"outputs":[],"source":["python trt_eval.py --onnx_model_file=output/ONNX/quant_model.onnx \\\n","                   --calibration_file=output/ONNX/calibration.cache \\\n","                   --precision_mode=int8 \\\n","                   --dataset_dir=dataset/coco/ \\\n","                   --val_image_dir=val2017 \\\n","                   --val_anno_path=annotations/instances_val2017.json"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.8.15 ('yolov7')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.15"},"vscode":{"interpreter":{"hash":"0783e26e129689f95a0c7d39013903d65f5dc93a6205c00e8bd888c786454962"}}},"nbformat":4,"nbformat_minor":0}
